{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import string\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.classify.util import apply_features\n",
    "from nltk.metrics.scores import (accuracy, precision, recall)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Selenium to get RMNP review data from All Trails\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument(\"--test-type\")\n",
    "options.binary_location = \"\"\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get('https://www.alltrails.com/parks/us/colorado/rocky-mountain-national-park')\n",
    "\n",
    "for i in np.arange(50):\n",
    "    submit_button = driver.find_elements_by_xpath('//*[@id=\"load_more\"]/div[2]/h3')[0]\n",
    "    submit_button.click()\n",
    "    time.sleep(10)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Comments: 1525\n"
     ]
    }
   ],
   "source": [
    "# Clean comments from reviews\n",
    "comments = soup.findAll(\"p\", {\"itemprop\": \"reviewBody\"})\n",
    "comments_clean = []\n",
    "for i in comments:\n",
    "    comments_clean.append(i.getText())\n",
    "\n",
    "comments_tokenized = []\n",
    "for i in comments_clean:\n",
    "    tknzr = TweetTokenizer(preserve_case=False)\n",
    "    tokens = tknzr.tokenize(i)\n",
    "    tokens = [w for w in tokens if w not in string.punctuation]\n",
    "    tokens = [w for w in tokens if w not in nltk.corpus.stopwords.words('english')]\n",
    "    tokens = [w for w in tokens if len(w) > 2]\n",
    "    comments_tokenized.append(tokens)\n",
    "\n",
    "print(\"Total Number of Comments: \"+ str(len(comments_tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Ratings: 1525\n"
     ]
    }
   ],
   "source": [
    "# Clean ratings from reviews\n",
    "ratings = soup.findAll(\"meta\", {\"itemprop\": \"ratingValue\"})\n",
    "\n",
    "ratings = ratings[1:len(ratings)]\n",
    "ratings_clean = []\n",
    "for i in ratings:\n",
    "    ratings_clean.append(i.attrs[\"content\"])\n",
    "\n",
    "print(\"Total Number of Ratings: \"+ str(len(ratings_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 5 star ratings 1106\n",
      "Number of 4 star ratings 334\n",
      "Number of 3 star ratings 64\n",
      "Number of 2 star ratings 12\n",
      "Number of 1 star ratings 9\n"
     ]
    }
   ],
   "source": [
    "# Breakdown number of reviews by rating\n",
    "print(\"Number of 5 star ratings \" + str(ratings_clean.count(\"5\")))\n",
    "print(\"Number of 4 star ratings \" + str(ratings_clean.count(\"4\")))\n",
    "print(\"Number of 3 star ratings \" + str(ratings_clean.count(\"3\")))\n",
    "print(\"Number of 2 star ratings \" + str(ratings_clean.count(\"2\")))\n",
    "print(\"Number of 1 star ratings \" + str(ratings_clean.count(\"1\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Reviews: 1525\n"
     ]
    }
   ],
   "source": [
    "# Combine comments and ratings into reviews\n",
    "alltrails_comments = list(zip(comments_tokenized,ratings_clean))\n",
    "\n",
    "print(\"Total Number of Reviews: \"+ str(len(alltrails_comments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature word extractor function\n",
    "words = []\n",
    "for i in comments_tokenized:\n",
    "    words.append((\" \").join(i))\n",
    "\n",
    "word_features = []\n",
    "word_features = (\" \").join(words)\n",
    "word_features = word_features.split(\" \")\n",
    "word_features = list(set(word_features))\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 915\n",
      "Training Set size: 610\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing data\n",
    "training_set, testing_set = train_test_split(alltrails_comments, test_size=0.4, random_state=1)\n",
    "print(\"Training set size: \"+ str(len(training_set)))\n",
    "print(\"Training Set size: \"+ str(len(testing_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6508196721311476\n",
      "Most Informative Features\n",
      "      contains(allowing) = True                1 : 5      =     95.4 : 1.0\n",
      "           contains(dog) = True                1 : 5      =     95.4 : 1.0\n",
      "         contains(nicer) = True                2 : 5      =     83.5 : 1.0\n",
      "         contains(horse) = True                2 : 5      =     83.5 : 1.0\n",
      "       contains(shorter) = True                2 : 5      =     83.5 : 1.0\n",
      "         contains(tours) = True                2 : 5      =     83.5 : 1.0\n",
      "       contains(counter) = True                2 : 5      =     83.5 : 1.0\n",
      "         contains(flies) = True                2 : 5      =     83.5 : 1.0\n",
      " contains(disappointing) = True                2 : 5      =     83.5 : 1.0\n",
      "      contains(compared) = True                2 : 5      =     83.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create classification model & display top 10 important words\n",
    "training_set = nltk.classify.util.apply_features(extract_features, training_set)\n",
    "testing_set = nltk.classify.util.apply_features(extract_features, testing_set)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print('Accuracy:', nltk.classify.util.accuracy(classifier, testing_set))\n",
    "classifier.show_most_informative_features(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction  2   3   4    5\n",
       "actual                    \n",
       "1           0   0   0    3\n",
       "2           0   1   1    3\n",
       "3           0   1   3   22\n",
       "4           0   6  27  104\n",
       "5           1  15  54  369"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "prediction = []\n",
    "actual = []\n",
    "for i, (feats, label) in enumerate(testing_set):\n",
    "    prediction.append(int(classifier.classify(feats)))\n",
    "    actual.append(int(label))\n",
    "    \n",
    "confmatrix = pd.DataFrame()\n",
    "confmatrix[\"prediction\"] = prediction\n",
    "confmatrix[\"actual\"] = actual\n",
    "pd.crosstab(confmatrix.actual, confmatrix.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Correct 5 star ratings: 0.8405466970387244\n",
      "% Correct 4 star ratings: 0.19708029197080293\n",
      "% Correct 3 star ratings: 0.038461538461538464\n",
      "% Correct 2 star ratings: 0.0\n",
      "% Correct 1 star ratings: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy by rating\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "for i, (feats, label) in enumerate(testing_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "print('% Correct 5 star ratings:', nltk.recall(refsets['5'], testsets['5']))\n",
    "print('% Correct 4 star ratings:', nltk.recall(refsets['4'], testsets['4']))\n",
    "print('% Correct 3 star ratings:', nltk.recall(refsets['3'], testsets['3']))\n",
    "print('% Correct 2 star ratings:', nltk.recall(refsets['2'], testsets['2']))\n",
    "print('% Correct 1 star ratings:', nltk.recall(refsets['1'], testsets['1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources:\n",
    "\n",
    "http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "\n",
    "https://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
    "        \n",
    "https://streamhacker.com/2010/06/16/text-classification-sentiment-analysis-eliminate-low-information-features/\n",
    "\n",
    "https://www.youtube.com/watch?v=zaIrQ3vMoTw\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
